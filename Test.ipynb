{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Jacksu20160407/Google_Colaboratory/blob/master/Test.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "5gm0DLIhmtEU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pytest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_mrkPnOnrsIr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install ipdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89So4isUkyje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ipdb as pdb\n",
        "import multiprocessing\n",
        "\n",
        "import numpy as np\n",
        "import pytest\n",
        "from csv import reader\n",
        "from csv import Sniffer\n",
        "import shutil\n",
        "from keras import optimizers\n",
        "from keras import initializers\n",
        "from keras import callbacks\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Dropout, add, dot, Lambda\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
        "from keras.utils.test_utils import get_test_data\n",
        "from keras.utils.test_utils import keras_test\n",
        "from keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "try:\n",
        "    from unittest.mock import patch\n",
        "except:\n",
        "    from mock import patch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mi0XcaJAop7r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_dim = 2\n",
        "num_hidden = 4\n",
        "num_classes = 2\n",
        "batch_size = 5\n",
        "train_samples = 20\n",
        "test_samples = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYYrYmUupA05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "154555b5-0a72-4008-9348-34a30e0decf1"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "%prun\n",
        "@keras_test\n",
        "def test_TerminateOnNaN():\n",
        "    np.random.seed(1337)\n",
        "    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n",
        "                                                         num_test=test_samples,\n",
        "                                                         input_shape=(input_dim,),\n",
        "                                                         classification=True,\n",
        "                                                         num_classes=num_classes)\n",
        "    pdb.set_trace()\n",
        "    y_test = np_utils.to_categorical(y_test)\n",
        "    y_train = np_utils.to_categorical(y_train)\n",
        "    cbks = [callbacks.TerminateOnNaN()]\n",
        "    model = Sequential()\n",
        "    initializer = initializers.Constant(value=1e5)\n",
        "    for _ in range(5):\n",
        "        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu',\n",
        "                        kernel_initializer=initializer))\n",
        "    model.add(Dense(num_classes, activation='linear'))\n",
        "    model.compile(loss='mean_squared_error',\n",
        "                  optimizer='rmsprop')\n",
        "\n",
        "    # case 1 fit\n",
        "    history = model.fit(X_train, y_train, batch_size=batch_size,\n",
        "                        validation_data=(X_test, y_test), callbacks=cbks, epochs=20)\n",
        "    loss = history.history['loss']\n",
        "    assert len(loss) == 1\n",
        "    assert loss[0] == np.inf\n",
        "\n",
        "    # case 2 fit_generator\n",
        "    def data_generator():\n",
        "        max_batch_index = len(X_train) // batch_size\n",
        "        i = 0\n",
        "        while 1:\n",
        "            yield (X_train[i * batch_size: (i + 1) * batch_size],\n",
        "                   y_train[i * batch_size: (i + 1) * batch_size])\n",
        "            i += 1\n",
        "            i = i % max_batch_index\n",
        "    history = model.fit_generator(data_generator(),\n",
        "                                  len(X_train),\n",
        "                                  validation_data=(X_test, y_test),\n",
        "                                  callbacks=cbks,\n",
        "                                  epochs=20)\n",
        "    loss = history.history['loss']\n",
        "    assert len(loss) == 1\n",
        "    assert loss[0] == np.inf or np.isnan(loss[0])\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}